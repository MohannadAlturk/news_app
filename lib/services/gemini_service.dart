import 'dart:convert';

import 'package:flutter_dotenv/flutter_dotenv.dart';  // For loading API key from .env
import 'package:google_generative_ai/google_generative_ai.dart';

class GeminiService {
  final String apiKey = dotenv.env['GEMINI_API_KEY']!;  // Load API key from .env


  Future<String?> translateArticlesJson(String articlesJsonString) async {
    // Set up the prompt for translating JSON content
    String prompt = """
Translate only the 'title' and 'description' fields in the JSON content below into ${jsonDecode(articlesJsonString)['targetLanguage']} language.

1. Translate only the text values of 'title' and 'description'. Do not change any other parts of the JSON.
2. Do not use double quotes (") within translated text. Use single quotes (') if needed inside text fields.
3. The JSON output should be fully formatted and ready to be parsed.

Content:
$articlesJsonString
""";

    final model = GenerativeModel(
      model: 'gemini-1.5-flash',
      apiKey: apiKey,
      generationConfig: GenerationConfig(
        temperature: 1,
        topK: 64,
        topP: 0.95,
        maxOutputTokens: 8192,
        responseMimeType: 'application/json', // Expecting JSON output
      ),
    );

    final chat = model.startChat(history: []);
    final content = Content.text(prompt);

    // Send the prompt to Gemini for translation
    final response = await chat.sendMessage(content);

    return response.text;  // Should return JSON as a string
  }

  // Method to summarize article content using Gemini 1.5 Flash API with a custom prompt
  Future<String?> summarizeArticle(String articleContent, {String? customPrompt}) async {
    final model = GenerativeModel(
      model: 'gemini-1.5-flash',
      apiKey: apiKey,
      generationConfig: GenerationConfig(
        temperature: 1,
        topK: 64,
        topP: 0.95,
        maxOutputTokens: 8192,
        responseMimeType: 'text/plain',
      ),
    );

    // Create the custom prompt
    String prompt = customPrompt ??
        "Summarize the following article in a consise and well-written way."
            "It should be easy to understand and contain the most necessary information,"
            "to get a good understanding of it in a short amount of time."
            "Return it as plain text without any formatting.";
    final fullPrompt = '$prompt\n\n$articleContent';

    final chat = model.startChat(history: []);
    final content = Content.text(fullPrompt);

    // Send the custom prompt along with the article content to Gemini
    final response = await chat.sendMessage(content);

    return response.text;  // Return the summary generated by Gemini
  }

  // Method to summarize article content using Gemini 1.5 Flash API with a custom prompt
  Future<String?> summarizeAndTranslateArticle(String articleContent, {String? customPrompt, String language = 'en'}) async {
    final model = GenerativeModel(
      model: 'gemini-1.5-flash',
      apiKey: apiKey,
      generationConfig: GenerationConfig(
        temperature: 1,
        topK: 64,
        topP: 0.95,
        maxOutputTokens: 8192,
        responseMimeType: 'text/plain',
      ),
    );

    // Create the custom prompt
    String prompt = customPrompt ??
        "Summarize the following article in a consise and well-written way."
        "It should be easy to understand and contain the most necessary information,"
        "to get a good understanding of it in a short amount of time."
        "Return it as plain text without any formatting. Return it in this language: $language ";
    final fullPrompt = '$prompt\n\n$articleContent';

    final chat = model.startChat(history: []);
    final content = Content.text(fullPrompt);

    // Send the custom prompt along with the article content to Gemini
    final response = await chat.sendMessage(content);
    String? summary = response.text;  // Return the summary generated by Gemini
    // String? translatedSummary = await translateSummary(summary, language: language);
    return summary;
  }

  Future<String?> translateSummary(String? articleContent, {String language = 'en'}) async {
    final model = GenerativeModel(
      model: 'gemini-1.5-flash',
      apiKey: apiKey,
      generationConfig: GenerationConfig(
        temperature: 1,
        topK: 64,
        topP: 0.95,
        maxOutputTokens: 8192,
        responseMimeType: 'text/plain',
      ),
    );

    // Create the custom prompt
    String prompt =
            "Translate the summary into this language Code: $language."
            "Do not add anything else, stick to the provided summary but only translate it."
            "Only return the summary in the provided language "
    ;
    final fullPrompt = '$prompt\n\n$articleContent';

    final chat = model.startChat(history: []);
    final content = Content.text(fullPrompt);

    // Send the custom prompt along with the article content to Gemini
    final response = await chat.sendMessage(content);

    return response.text;  // Return the summary generated by Gemini
  }

  Future<String?> translateQuery(String? query, {String language = 'en'}) async {
    final model = GenerativeModel(
      model: 'gemini-1.5-flash',
      apiKey: apiKey,
      generationConfig: GenerationConfig(
        temperature: 0,
        topK: 0,
        topP: 0,
        maxOutputTokens: 100,
        responseMimeType: 'text/plain',
      ),
    );

    // Create the custom prompt
    String prompt =
        "Translate the following user query into this language Code: $language."
        "Do not add anything else, stick to the provided query but only translate it."
        "Only return the query in the provided language."
        "Example: User Query: Mond"
        "Your answer: moon"
    ;
    final fullPrompt = '$prompt\n\n$query';

    final chat = model.startChat(history: []);
    final content = Content.text(fullPrompt);

    // Send the custom prompt along with the article content to Gemini
    final response = await chat.sendMessage(content);

    return response.text;  // Return the summary generated by Gemini
  }
}
